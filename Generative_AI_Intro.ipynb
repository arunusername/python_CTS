{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuSRu90vhG9U"
      },
      "outputs": [],
      "source": [
        "f=open('OpenAIKey.txt','r')\n",
        "key = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzCv4iZzXrAe",
        "outputId": "c5f88044-ac3e-41d6-c651-bf670766b706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install openai\n",
        "!pip install openai==0.28.1\n",
        "import openai\n",
        "openai.api_key = key\n",
        "\n",
        "def Generate_Content(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q127Y4DmJn_g",
        "outputId": "ff27226a-8128-41ab-b78c-4f5684be24f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a Python code that checks if a number is prime or not:\n",
            "\n",
            "```python\n",
            "def is_prime(number):\n",
            "    if number <= 1:\n",
            "        return False\n",
            "    if number <= 3:\n",
            "        return True\n",
            "    if number % 2 == 0 or number % 3 == 0:\n",
            "        return False\n",
            "    divisor = 5\n",
            "    while divisor * divisor <= number:\n",
            "        if number % divisor == 0 or number % (divisor + 2) == 0:\n",
            "            return False\n",
            "        divisor += 6\n",
            "    return True\n",
            "\n",
            "# Example usage\n",
            "number = int(input(\"Enter a number: \"))\n",
            "if is_prime(number):\n",
            "    print(number, \"is a prime number\")\n",
            "else:\n",
            "    print(number, \"is not a prime number\")\n",
            "```\n",
            "\n",
            "This code defines a function `is_prime()` that takes a number as input and returns `True` if the number is prime, and `False` otherwise.\n",
            "\n",
            "The `is_prime()` function checks the following conditions:\n",
            "- If the number is less than or equal to 1, it returns `False`, as prime numbers are greater than 1.\n",
            "- If the number is 2 or 3, it returns `True`, as they are prime numbers.\n",
            "- If the number is divisible by 2 or 3, it returns `False`, as prime numbers are not divisible by any number other than 1 and themselves.\n",
            "- The function then checks for prime numbers using a common optimization technique that ignores all numbers divisible by 2 or 3. It starts by checking if the number is divisible by 5 or 7, then increments the divisor by 6 for subsequent checks (divisors 5 and 7 are both 6k ± 1). This optimization reduces the number of operations needed to check for prime numbers.\n",
            "- If the function completes the loop without finding any divisor, it returns `True`.\n",
            "\n",
            "You can test this code by entering a number and it will output whether it is prime or not.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize Alice in the wonderland in 3 sentences.\n",
        "\"\"\"\n",
        "\n",
        "prompt1 = f\"\"\"\n",
        "write python code to check if a number is prime\n",
        "\"\"\"\n",
        "\n",
        "response = Generate_Content(prompt1)\n",
        "print(response)\n",
        "\n",
        "f=open('response.txt','w')\n",
        "f.write(response)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Written by Google\n",
        "\n",
        "# prompt: write python code to create 2 text files and merge them into a third file\n",
        "\n",
        "\n",
        "f1 = open(\"file1.txt\", \"w\")\n",
        "f1.write(\"This is file 1.\\n\")\n",
        "f1.close()\n",
        "\n",
        "f2 = open(\"file2.txt\", \"w\")\n",
        "f2.write(\"This is file 2.\\n\")\n",
        "f2.close()\n",
        "\n",
        "with open(\"merged.txt\", \"w\") as outfile:\n",
        "    for fname in [\"file1.txt\", \"file2.txt\"]:\n",
        "        with open(fname) as infile:\n",
        "            outfile.write(infile.read())\n"
      ],
      "metadata": {
        "id": "jL37V0VCW47G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZR11TLLdzO"
      },
      "source": [
        "### Prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxx_slyQG3s"
      },
      "source": [
        "**Deriving Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNE9sHzcQVtu"
      },
      "outputs": [],
      "source": [
        "review1 = \"\"\"\n",
        "The cashier had no care what so ever on what I had to\n",
        "say it still ended up being wayyy overpriced.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ljpvCSRRKb",
        "outputId": "bf66097f-3794-4343-ca41-6fc442686f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the product review is negative.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "Review text: '''{review1}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzFqeBORZDF",
        "outputId": "f13f4137-e8c5-40f2-9e11-c2295c2d9ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unhappy, frustrated, annoyed\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{review1}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm9Rh7B7RdBT",
        "outputId": "c5f36f2a-2ce7-4fa5-9349-24a625d76f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{review1}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ndzo9xSgH_"
      },
      "source": [
        "**Expanding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqxNkattS2OR",
        "outputId": "36164ad6-184f-4896-b957-5a64890ead54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Valued Customer,\n",
            "\n",
            "Thank you for taking the time to share your review. We truly appreciate your feedback.\n",
            "\n",
            "We sincerely apologize for the unsatisfactory experience you had with our cashier. We understand how important it is to be attentive and responsive to our customers' needs. We assure you that we will address this issue with our staff to ensure that it does not happen again in the future.\n",
            "\n",
            "If there is anything else that we can do to assist you, please do not hesitate to contact our customer service department. They are available to assist you with any concerns or questions you may have.\n",
            "\n",
            "Once again, we apologize for any inconvenience caused. We appreciate your support and value your business.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review1}```\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcARGNEUcACQ"
      },
      "source": [
        "**Moderation API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iGX5PDa0mc",
        "outputId": "3f19efd5-1247-4a58-fb6b-acca06f960f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: {\n",
            "  \"sexual\": false,\n",
            "  \"hate\": false,\n",
            "  \"harassment\": false,\n",
            "  \"self-harm\": false,\n",
            "  \"sexual/minors\": false,\n",
            "  \"hate/threatening\": false,\n",
            "  \"violence/graphic\": false,\n",
            "  \"self-harm/intent\": false,\n",
            "  \"self-harm/instructions\": false,\n",
            "  \"harassment/threatening\": false,\n",
            "  \"violence\": true\n",
            "}\n",
            "Category Scores: {\n",
            "  \"sexual\": 3.790656410274096e-05,\n",
            "  \"hate\": 6.624864454352064e-06,\n",
            "  \"harassment\": 0.0003785671724472195,\n",
            "  \"self-harm\": 7.037100294837728e-05,\n",
            "  \"sexual/minors\": 3.6383440260578936e-07,\n",
            "  \"hate/threatening\": 5.2216396397852805e-06,\n",
            "  \"violence/graphic\": 0.35266315937042236,\n",
            "  \"self-harm/intent\": 3.429163143664482e-06,\n",
            "  \"self-harm/instructions\": 1.7580259026317435e-08,\n",
            "  \"harassment/threatening\": 0.0004090997972525656,\n",
            "  \"violence\": 0.7759827375411987\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = openai.Moderation.create(\n",
        "  input=\"Input text goes here while at war with intense gunfire ripping human limbs\"\n",
        ")\n",
        "\n",
        "categories = response['results'][0]['categories']\n",
        "category_scores = response['results'][0]['category_scores']\n",
        "\n",
        "print(\"Categories:\", categories)\n",
        "print(\"Category Scores:\", category_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}